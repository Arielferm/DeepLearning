# -*- coding: utf-8 -*-
"""8_Autoencoders.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DjwYS55OrD2FdZhDgT1CODS4-Vt4Wdfi
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

import tensorflow as tf
from tensorflow import keras

#utilizaremos tensorboard para mostrar como se usa
# %load_ext tensorboard
#usemos hora actual para etiquetar los logs de cada fit, y que no se sobreescriban
import datetime, os

"""A continuación introduciremos un ejemplo de Autoencoders (*inspirados [en este artículo](https://blog.keras.io/building-autoencoders-in-keras.html)*)

# El autoencoder más sencillo

Un autoencoder es una red neuronal cuyos input y output layers tienen la misma cantidad de neuronas, y tiene un layer oculto de una dimensión menor. Este se entrena para reproducir los inputs, y si lo logra eficientemente, el layer oculto habrá codificado toda la información de nuestro training set en un vector de dimensión menor.

Es un algoritmo auto-supervisado, de reducción dimensional. Sus aplicaciones son varias, como por ejemplo limpiar ruido, detectar anomalías y obtener representaciones de baja dimensionalidad que sean densas en información.

Hagamos el autoencoder más sencillo. Tomaremos imágenes de 28x28 = 784 píxeles, con valores entre cero y uno. Lo pasaremos por un layer oculto (que contiene la información "codificada") de dimensión 32, y luego decodificaremos esto con un layer de 784 neuronas con activación sigmoide (y así tener 784 "píxeles" decodificados entre 0 y 1).
"""

# Este es el tamaño de la representación interna (latente)
encoding_dim = 32  # 32 floats -> un factor de compresion  24.5 (input_size=784)

#Usamos la api funcional
#input placeholder
input_img = keras.layers.Input(shape=(784,))
#este layer tiene la representacion latente "codificada":
encoded = keras.layers.Dense(encoding_dim, activation='relu')(input_img)
#este layer tiene la reconstruccion de la imagen (pixeles en [0,1])
decoded = keras.layers.Dense(784, activation='sigmoid')(encoded)

# Definimos el modelo del autoencoder
autoencoder = keras.models.Model(input_img, decoded)

keras.utils.plot_model(autoencoder, show_shapes=True)

"""De este modelo, podemos aislar las dos componentes: El encoder

Para compilarlo, tenemos que definir una loss. Podemos, por ejemplo, comparar pixel por pixel si son iguales o no, y como aplicamos una sigmoide una forma seria diciendo que es clasificacion binaria (mas precisamente, 784 clasificaciones binarias en paralelo, una para cada pixel hecha con cada neurona del decoder)
"""

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

"""Probemos como funciona con imagenes, por ejemplo los digitos escritos a mano del MNIST:"""

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

#normalizamos los pixeles [0,1]
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
#y le hacemos un flatten: transformamos la matriz de 28x28 en un vector de 784
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print (x_train.shape)
print (x_test.shape)

"""Ahora fiteemos. Y usemos el callback de tensorboard asi ven como se usa"""

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

#fit
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[tensorboard_callback])

# Commented out IPython magic to ensure Python compatibility.
#inicializamos tensorboard
# %tensorboard --logdir logs

"""Ahora veamos sus resultados. Tomemos imagenes del conjunto de test, codifiquémosla y decodifiquémosla."""

# Las pasamos por el encoder:
decoded_imgs = autoencoder.predict(x_test)

n = 10  # cuantos digitos imprimimos
plt.figure(figsize=(20, 4))
for i in range(n):
    # original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # reconstrucción
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

encoded_imgs[0]



# mapea el input a la representación codificada de tamaño 32
encoder = keras.models.Model(input_img, encoded)
keras.utils.plot_model(encoder, show_shapes=True)

# Las pasamos por el encoder:
decoded_imgs = encoder.predict(x_test)
n = 10  # cuantos digitos imprimimos
plt.figure(figsize=(20, 4))
for i in range(n):
    # original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # reconstrucción
    ax = plt.subplot(2, n, i + 1 + n)
    plt.plot(decoded_imgs[i])
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

"""## Ejercicio 1: Probar con diferentes número de Neuronas y de Capas. RECUERDE QUE ES UN AUTOENCODER... "Baja" y "Sube" Simétrico

# Deep Autoencoder

Por supuesto, entre el input y el layer codificado (encoder) uno puede poner tantos layers como quiera. Lo mismo entre el layer codificado y el de output (decoder). En general, que el autoencoder sea simétrico suele ser una elección razonable.
"""

input_img = keras.layers.Input(shape=(784,))
encoded = keras.layers.Dense(128, activation='relu')(input_img)
encoded = keras.layers.Dense(64, activation='relu')(encoded)
encoded = keras.layers.Dense(32, activation='relu')(encoded)

decoded = keras.layers.Dense(64, activation='relu')(encoded)
decoded = keras.layers.Dense(128, activation='relu')(decoded)
decoded = keras.layers.Dense(784, activation='sigmoid')(decoded)

deep_autoencoder = keras.models.Model(input_img, decoded)

deep_autoencoder.summary()

deep_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,
                                                  restore_best_weights=True)

deep_autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[tensorboard_callback,early_stopping_cb],
                verbose=False)

decoded_imgs = deep_autoencoder.predict(x_test)

n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

# En el deepAutoencoder probar con diferentes número de neuronas y capas de neuronas. Recuerde que “Baja” y “Sube” simétrico.

import matplotlib.pyplot as plt
input_img = keras.layers.Input(shape=(784,))
encoded = keras.layers.Dense(512, activation='relu')(input_img)
encoded = keras.layers.Dense(256, activation='relu')(encoded)
encoded = keras.layers.Dense(128, activation='relu')(encoded)
encoded = keras.layers.Dense(64, activation='relu')(encoded)
encoded = keras.layers.Dense(32, activation='relu')(encoded)

decoded = keras.layers.Dense(64, activation='relu')(encoded)
decoded = keras.layers.Dense(128, activation='relu')(decoded)
decoded = keras.layers.Dense(256, activation='relu')(decoded)
decoded = keras.layers.Dense(512, activation='relu')(decoded)
decoded = keras.layers.Dense(784, activation='sigmoid')(decoded)

deep_autoencoder = keras.models.Model(input_img, decoded)

deep_autoencoder.summary()
deep_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,
                                                  restore_best_weights=True)

deep_autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[tensorboard_callback,early_stopping_cb],
                verbose=False)
decoded_imgs = deep_autoencoder.predict(x_test)

n = 10  # how many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

"""# Convolutional

Dado que estamos trabajando con imágenes, quizás lo mejor sería utilizar encoders y decoders que hagan uso de layers convolucionales, y así analizar la imagen de una manera mucho más eficiente que con redes densas.
"""

keras.backend.clear_session()

input_img = keras.layers.Input(shape=(28, 28, 1))

#Encoder: Conv -> MaxPool (x2)
x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)
x = keras.layers.MaxPooling2D((2, 2), padding='same')(x)
x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
encoded = keras.layers.MaxPooling2D((2, 2), padding='same')(x)

# la representacion aca es de shape (7, 7, 32) i.e. 128-dimensional

#Decoder: Conv -> UpSampling (x2)
x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)
x = keras.layers.UpSampling2D((2, 2))(x)
x = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)
x = keras.layers.UpSampling2D((2, 2))(x)
decoded = keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

conv_autoencoder = keras.models.Model(input_img, decoded)
conv_autoencoder.compile(loss='binary_crossentropy')

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

#normalizamos los pixeles [0,1]
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.

#logdir = os.path.join("logs", datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))
#tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)
early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,
                                                  restore_best_weights=True)

hist = conv_autoencoder.fit(x_train, x_train,
                epochs=100,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test, x_test),
                callbacks=[early_stopping_cb])

"""Veamos como podemos utilizar esta red para limpiar el ruido de imágenes. Estas imágenes ruidosas no se parecen a las del training set, por lo cual el autoencoder lo mapeará a una representación interna que se parece mucho a la del numero que representa, y al decodificarla obtendremos una imagen mas similar a las de nuestro training set (sin ruido)."""

#añadimos ruido aleatorio a nuestros pixels
noise_factor = 0.2
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape)
#nos aseguramos que estos nuevos pixels saturen esten comprendidos entre 0 y 1, donde saturan
x_train_noisy = np.clip(x_train_noisy, 0., 1.)
x_test_noisy = np.clip(x_test_noisy, 0., 1.)

"""Veamos como quedaron las imagenes con ruido"""

n = 10
plt.figure(figsize=(20, 2))
print("Original")
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
print("Noisy")
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_noisy[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

"""Ahora limpiémoslas pasando por el autoencoder:"""

x_test_cleaned = conv_autoencoder.predict(x_test_noisy)

"""A ver como quedó:"""

n = 10

print("Original")
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

print("Noisy")
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_noisy[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

plt.figure(figsize=(20, 2))
print("Limpias")
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_cleaned[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

"""Por supuesto, podemos iterativamente pasarla por el autoencoder, pero esto irá distorcionando la imagen cada ves más:"""

x_test_cleaned = conv_autoencoder.predict(x_test_cleaned)
plt.figure(figsize=(20, 2))
print("Limpias")
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_cleaned[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

"""## Ejercicio 2: Probar cómo "limpia" la red "Densa"
"""

x_test_cleaned = deep_autoencoder.predict(x_test_noisy)

n = 10

print("Original")
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

print("Noisy")
plt.figure(figsize=(20, 2))
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_noisy[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()

plt.figure(figsize=(20, 2))
print("Limpias")
for i in range(n):
    ax = plt.subplot(1, n, i+1)
    plt.imshow(x_test_cleaned[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()