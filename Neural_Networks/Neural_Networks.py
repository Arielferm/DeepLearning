# -*- coding: utf-8 -*-
"""6_NeuralNetworks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UJ3SbR-3J3hMOtK8JeVtt6Q3MzD1NXri
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

#The stars
import tensorflow as tf
from tensorflow import keras

tf.__version__

"""# Datos: Clasificacion de numeros (MNIST)

Asi como sklearn trae utilidades para cargar datasets estandar, keras también trae. En general, keras puede aceptar datasets en forma de Numpy Arrays (como sklearn), pero también trae una clase Dataset que esta optimizada para cargar datos (incluso si son mas grandes que la memoria RAM del equipo).
"""

mnist = keras.datasets.mnist
(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()

"""En Datasets grandes, CrossValidation puede ser muy costoso, por lo cual se recomienda separar un conjunton de validación aparte del training. Esto hacemos a continuación.

También normalizamos los píxeles (que van de 0 a 255) para que estén entre 0 y 1.
"""

#Separo en entrenamiento y validacion, y normalizo los pixeles
X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.
y_valid, y_train = y_train_full[:5000], y_train_full[5000:]
X_test = X_test / 255.

print(X_train.shape)

# Dibujo alguna de las entradas para ver la base de datos que descargamos:
plt.imshow(X_train[0], cmap=plt.get_cmap('gray'))

# muestra el plot
plt.show()

"""Los targets son numericos, del 0 al 9. Podemos guardar las etiquetas asi nos es mas facil analizar que tan bien o mal funciona nuestro modelo:"""

class_names = ["Num 0", "Num 1", "Num 2", "Num 3", "Num 4",
               "Num 5", "Num 6", "Num 7", "Num 8", "Num 9"]

n_rows = 4
n_cols = 10
plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))
for row in range(n_rows):
    for col in range(n_cols):
        index = n_cols * row + col
        plt.subplot(n_rows, n_cols, index + 1)
        plt.imshow(X_train[index], cmap="binary", interpolation="nearest")
        plt.axis('off')
        plt.title(class_names[y_train[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()

"""# Definir un modelo

Hay tres formas de definir modelos:
* Una es utilizando la clase de ``keras.models.Sequential``, que es apta para modelos donde solamente Layers adyacentes se encuentran conectados entre sí.
* Otra es API funcional, que provee mucha mas flexibilidad, ya que se puede construir cualquier clase de red dirigida acíclica.
* La ultima forma, es con SubClassing, es decir definiendo nuestras propias clases que hereden de las definidas en Keras, lo cual nos permite extender Keras para nuestras necesidades específicas, aunque no es recomendable a menos que realmente sepamos lo que estamos haciendo.

Si bien ahora quizás les sea mas sencillo utilizar la API secuencial, aprender a utilizar la API funcional es casi igual de fácil y provee mas flexibilidad, asi que es la forma que recomiendo de aprender a usar.

## API Secuencial

Podemos crear un modelo, e ir añadiendo Layers sobre la marcha.
"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

#Creo un modelo secuencial

model = keras.models.Sequential()
#Y le voy agregando layers
model.add(keras.layers.Flatten(input_shape=[28, 28])) #matriz->vector (como np.ravel)
model.add(keras.layers.Dense(300, activation="relu")) #hidden 1
model.add(keras.layers.Dense(100, activation="relu")) #hidden 2
model.add(keras.layers.Dense(10, activation="softmax")) #output

"""# Compilar y visualizar

Una vez que hemos definido nuestro modelo, es necesario que lo "compilemos", entonces Keras creará el gráfico computacional en TensorFlow de acuerdo a como lo hemos definido.
"""

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])



"""Podemos acceder a los diferentes Layers, mediante el atributo ``.layers``"""

model.layers

"""Y También podemos imprimir un resumen de nuestro modelo, asi como un lindo grafico de el:"""

model.summary()

keras.utils.plot_model(model, "my_fashion_mnist_model.png", show_shapes=True)

"""# Entrenar

Entrenar es tan facil como hacer un ``.fit``, donde podemos especificar muchas cosas como épocas, datos de validación (que evaluará al final de cada época), métricas, etc.

El método devuelve un objeto de Historia, con toda la información del entrenamiento (en forma de diccionarios), que podremos utilizar para analizar el modelo.
"""

history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))

"""Examinemos el diccionario de parámetros del fit:"""

history.params

history.history.keys()

"""Podemos usar el atributo "history" que nos da un diccionario, para plotear las métricas que usamos."""

import pandas as pd

pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1)
plt.show()

"""# Evaluar y predecir

Evaluar en un conjunto de Test, o hacer predicciones, es sumamente fácil:
"""

model.evaluate(X_test, y_test)

X_new = X_test[:3]
y_proba = model.predict(X_new)
y_proba.round(2)

y_pred = model.predict(X_new)
y_pred

y_pred = np.argmax(y_proba, axis=-1)
y_pred

np.array(class_names)[y_pred]

plt.figure(figsize=(7.2, 2.4))
for index, image in enumerate(X_new):
    plt.subplot(1, 3, index + 1)
    plt.imshow(image, cmap="binary", interpolation="nearest")
    plt.axis('off')
    plt.title(class_names[y_test[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()

"""## Ejercicio 1: Modifique la Red para que tenga en las capas 50 y 20 neuronas. Que resultados Obtengo?"""

keras.backend.clear_session()
np.random.seed(42)
tf.random.set_seed(42)

#Creo un modelo secuencial 2

model = keras.models.Sequential()
#Y le voy agregando layers
model.add(keras.layers.Flatten(input_shape=[28, 28])) #matriz->vector (como np.ravel)
model.add(keras.layers.Dense(50, activation="relu")) #hidden 1
model.add(keras.layers.Dense(20, activation="relu")) #hidden 2
model.add(keras.layers.Dense(10, activation="softmax")) #output

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="sgd",
              metrics=["accuracy"])

keras.utils.plot_model(model, "my_fashion_mnist_model.png", show_shapes=True)

history = model.fit(X_train, y_train, epochs=20,
                    validation_data=(X_valid, y_valid))

model.evaluate(X_test, y_test)

X_new = X_test[:3]
y_proba = model.predict(X_new)
y_proba.round(2)

y_pred = model.predict(X_new)
y_pred

y_pred = np.argmax(y_proba, axis=-1)
y_pred

np.array(class_names)[y_pred]

plt.figure(figsize=(7.2, 2.4))
for index, image in enumerate(X_new):
    plt.subplot(1, 3, index + 1)
    plt.imshow(image, cmap="binary", interpolation="nearest")
    plt.axis('off')
    plt.title(class_names[y_test[index]], fontsize=12)
plt.subplots_adjust(wspace=0.2, hspace=0.5)
plt.show()

"""Los resultados que obtenidos a son: en términos de precisión, como precisión de prueba, esta es algo menor en comparación con el modelo original de 300 y 100 neuronas debido a la reducción de la capacidad del modelo. En caso del tiempo de entrenamiento, se observa una reducción de tiempo, ya que, con menos neuronas, el tiempo de entrenamiento disminuye debido a la reducción en la cantidad de parámetros a entrenar."""